<translations>
<comment></comment>
<translationBlock>
	<id>nl-1715</id>
	<key><![CDATA[Find a bug in this page? %sEdit this page yourself, then submit a pull request.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-1728</id>
	<key><![CDATA[Usage]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3354</id>
	<key><![CDATA[3 - Procedure execution times are shown. The parameters passed to the procedure will be displayed as well, so you can differentiate between various procedure executions.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3355</id>
	<key><![CDATA[The profiler shows different information based on your granularity, but this chart shows the general types of  information shown. As you go to more verbose, more information is shown, as well as the lower levels' information.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3356</id>
	<key><![CDATA[The profiler is controlled with the profiler.config file, which is created in the CommandHelper directory. There are a  few settings of interest, each documented in the file. To turn profiling on, set the "profiler-on" switch to true. Note  that profiling can introduce up to a one millisecond lag '''per triggered profile point''', (untriggered profile points  take about .001ms) so turning profiling on and leaving it on during normal server operation is not recommended.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3357</id>
	<key><![CDATA[Setting the granularity to a higher setting will cause more profile points to be triggered, so if debugging in a live  scenario, it is best to turn the granularity to a lower number. Typically, 1 is sufficient to identify general slow  points in your script, which can then be moved to a test server, with a high granularity.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3358</id>
	<key><![CDATA[4 - File IO times are shown. Sometimes, file IO will appear out of sequence, because IO is sometimes asynchronous, however, the times will still be recorded. The following functions run times will be shown: read(), get_values(), get_value(), store_value(), clear_value(), has_value().]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3359</id>
	<key><![CDATA[What types of information is profiled?]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3360</id>
	<key><![CDATA[1 - Only high level information is shown about how long aliases, events, execution queue, and set_timeout/set_interval tasks took. Compilation of all MethodScript files is logged.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3361</id>
	<key><![CDATA[MethodScript Inefficiencies]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3362</id>
	<key><![CDATA[Results can't really be compared with each other, unless it came from the same server under similar loads. The results are only meaningful when compared against benchmarks, which can be set by running a few simple commands that do almost nothing, and comparing against that, or comparing against two different scripts run at the same time.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3363</id>
	<key><![CDATA[Comparing Results]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3364</id>
	<key><![CDATA[Sometimes, the java garbage collector introduces slowness, which can't be controlled at all. The profiler can't do anything about this, but it will tell you when the GC was run on the individual profile points, which will allow you to adjust your times accordingly. This will typically invalidate that set of results however, so it is good to know what results are considered "calibrated". The Garbage Collector tends to add at LEAST 5 ms, though this will vary greatly from machine to machine.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3365</id>
	<key><![CDATA[Java Garbage Collection]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3366</id>
	<key><![CDATA[The profiler is a built in mechanism to assist you in debugging troublesome scripts that take longer than expected. In  general, CH is designed to be fast; performance is a key concern, but being that you have very fine control over its  operation, it is always possible to make a poorly designed script that takes too long to complete. Various mechanisms  exist to help you fix a script that takes too long (namely the [[%s|Execution Queue]]) but  ''identifying'' a laggy script can be a challenge. This is where the profiler comes in.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3367</id>
	<key><![CDATA[It is possible that you identify slow spots in MethodScript itself. That is great! Setting the granularity to 5 will  spit out how long each and every native function takes, and if you find that there are functions that take exceedingly  long, then file a bug report, and hopefully performance can be improved.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3368</id>
	<key><![CDATA[5 - Every single function is individually profiled. The parameters passed to each function will be shown as well. WARNING: This is extremely CPU intensive, and should only be used on a test server. Note that execution times may appear out of order when using asynchronous tasks, such as set_timeout, etc. This is normal. Compilation times are also logged, per file.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-3369</id>
	<key><![CDATA[2 - Loop times are shown; for, foreach, while, and dowhile. The parameters passed to the loops will be displayed as well, so you can differentiate between various loop sizes. Compilation of MethodScript files are individually logged.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5152</id>
	<key><![CDATA[About]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5153</id>
	<key><![CDATA[Home]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5154</id>
	<key><![CDATA[Privacy Policy]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5155</id>
	<key><![CDATA[Sponsors]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5156</id>
	<key><![CDATA[Help]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5157</id>
	<key><![CDATA[Team. All rights reserved.]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
<translationBlock>
	<id>nl-5158</id>
	<key><![CDATA[Docs]]></key>
	<comment></comment>
	<translation></translation>
	<auto></auto>
</translationBlock>
</translations>
